{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818af80f-97e8-4c8f-a8c4-e642d827fd47",
   "metadata": {},
   "source": [
    "# 10 Mengenal Bag of word & Stop Word Filteringg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60f0584-2c3d-484b-90b2-3f2a0eabf24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distributions include the Linux kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daftar kalimat yang akan digunakan sebagai corpus\n",
    "corpus = [\n",
    "    'Linux has been around since the mid-1990s.',  # Menginformasikan keberadaan Linux sejak pertengahan tahun 1990-an\n",
    "    'Linux distributions include the Linux kernel.',  # Menyebutkan bahwa distribusi Linux mencakup kernel Linux\n",
    "    'Linux is one of the most prominent open-source software.'  \n",
    "    # Menyatakan bahwa Linux adalah salah satu perangkat lunak open-source yang paling menonjol\n",
    "]\n",
    "\n",
    "# Menampilkan corpus yang telah didefinisikan\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13a83b-51cc-4438-bf3f-586eebeca694",
   "metadata": {},
   "source": [
    "**Bag of Words model dengan CountVectorizer**\r\n",
    "\r\n",
    "Bag of Words model dapat diterapkan dengan memanfatkan CountVectorizer.\r\n",
    "\r\n",
    "Cara Kerja CountVectorize- r:\r\n",
    "\r\n",
    "Tokenisasi : Memecah teks menjadi kata-kata (token) indivi- dual.\r\n",
    "Pembersihan Teks : Mengubah semua teks menjadi huruf kecil dan menghapus tanda-  baca.\r\n",
    "Membangun Kosakata : Membuat daftar kata-kata unik yang ditemukan dalam seluruh - corpus.\r\n",
    "Membuat Vektor Film : Menghitung frekuensi kemunculan setiap kata dalam setiap dokumen dan membentuk matrik\n",
    "s fitur.\r\n",
    "Fitur Utama CountVec- torizer:\r\n",
    "\r\n",
    "Lowercasing : CountVectorizer mengonversi semua teks menjadi h- uruf kecil.\r\n",
    "Stop Words : Dapat diatur untuk menghapus kata-kata umum yang tidak memberikan infor- masi penting\r\n",
    "N-grams : Dapat dikonfigurasi untuk mempertimbangkan ko- mbinasi kata.\r\n",
    "Binary Mode : Dapat diatur untuk hanya menunjukkan keberadaan atau ketidakhadiran kata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6937f2-a4a0-406f-b289-a1000ecf3908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CountVectorizer dari pustaka scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Inisialisasi CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Menerapkan fit_transform pada corpus untuk tokenisasi dan menghitung frekuensi kata\n",
    "# Mengonversi hasilnya menjadi matriks padat (dense matrix)\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "\n",
    "# Menampilkan matriks fitur yang dihasilkan\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d72b50d-d767-4c41-8a5c-7831ef45e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990s', 'around', 'been', 'distributions', 'has', 'include', 'is',\n",
       "       'kernel', 'linux', 'mid', 'most', 'of', 'one', 'open', 'prominent',\n",
       "       'since', 'software', 'source', 'the'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mendapatkan daftar fitur (kata-kata unik) yang dihasilkan dari proses tokenisasi\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0e54a-bc22-43b5-ac64-c555979f086d",
   "metadata": {},
   "source": [
    "**Euclidean Distance untuk mengukur kedekatan/jarak antar dokumen (vector)**\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d222c24-145d-4c58-8469-13e084272db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarak dokumen 1 dan 2: [[3.16227766]]\n",
      "Jarak dokumen 1 dan 3: [[3.74165739]]\n",
      "Jarak dokumen 2 dan 3: [[3.46410162]]\n"
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import euclidean_distances dari pustaka sklearn.metrics.pairwise\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Looping untuk menghitung jarak antara setiap pasangan dokumen menggunakan Euclidean distance\n",
    "for i in range(len(vectorized_X)):\n",
    "    for j in range(i, len(vectorized_X)):\n",
    "        # Menghindari perhitungan jarak antara dokumen yang sama\n",
    "        if i == j:\n",
    "            continue\n",
    "        # Mengonversi matriks vectorized_X menjadi tipe data numpy array\n",
    "        X_i = np.asarray(vectorized_X[i])\n",
    "        X_j = np.asarray(vectorized_X[j])\n",
    "        # Menghitung jarak antara dua dokumen menggunakan Euclidean distance\n",
    "        jarak = euclidean_distances(X_i, X_j)\n",
    "        # Menampilkan hasil jarak antara dua dokumen\n",
    "        print(f'Jarak dokumen {i+1} dan {j+1}: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efadeabe-f5b0-4efb-80fd-babce8f715b7",
   "metadata": {},
   "source": [
    "**Stop Word Filtering pada text**\n",
    "\n",
    "Stop Word Filtering menyederhanakan representasi text dengan mengabaikan beberapa kata seperti determiners (the, a, an), auxiliary verbs (do, be, will), dan prepositions (on, in, at).\n",
    "Referensi: https://en.wikipedia.org/wiki/Stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93486f3d-ef88-4f30-8d0f-004001a51257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distributions include the Linux kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e794f00-7dde-44df-9b5c-5415db3471f7",
   "metadata": {},
   "source": [
    "**Stop Word Filtering dengan CountVectorizer**\n",
    "Stop Word Filtering juga dapat diterapkan dengan memanfaatkan CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1f0a929-c1d5-4b7c-9ae6-895f19ec7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CountVectorizer dari pustaka scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Inisialisasi CountVectorizer dengan mengatur stop words ke 'english'\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Menerapkan fit_transform pada corpus untuk tokenisasi dan menghitung frekuensi kata\n",
    "# Mengonversi hasilnya menjadi matriks padat (dense matrix)\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "\n",
    "# Menampilkan matriks fitur yang dihasilkan\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd99c3b-bfba-46e0-859e-f5f6b62fcf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990s', 'distributions', 'include', 'kernel', 'linux', 'mid',\n",
       "       'open', 'prominent', 'software', 'source'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mendapatkan daftar fitur (kata-kata unik) yang dihasilkan dari proses tokenisasi\n",
    "vectorizer.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
